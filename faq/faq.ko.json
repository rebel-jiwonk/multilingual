[
  {
    "category": "SDK 사용법",
    "lang": "ko",
    "faqs": [
      {
        "title": "RBLN SDK는 어떤 AI 프레임워크와 라이브러리를 지원하나요?",
        "slug": "rbln-sdk는-어떤-ai-프레임워크와-라이브러리를-지원하나요?",
        "tags": [
          "frameworks",
          "libraries"
        ],
        "body": "<p>RBLN SDK는 PyTorch 및 TensorFlow 기반 모델을 지원하며, Hugging Face Transformers/Diffusers 라이브러리와의 연동도 가능합니다.</p>\n<p>지속적인 업데이트를 통해 주요 AI 프레임워크와의 호환성을 강화하고 있습니다.</p>\n",
        "author": "Kwak Jiwon",
        "createdDate": "2025-04-07",
        "fileName": "ko/faq_7.ko.md",
        "order": "1"
      },
      {
        "title": "기존 PyTorch 또는 TensorFlow 모델을 RBLN SDK로 컴파일하려면 코드 수정이 필요한가요?",
        "slug": "기존-pytorch-또는-tensorflow-모델을-rbln-sdk로-컴파일하려면-코드-수정이-필요한가요?",
        "tags": [
          "model",
          "compile"
        ],
        "body": "<p>대부분의 경우 최소한의 코드 수정만으로 RBLN SDK를 사용할 수 있습니다.</p>\n<ul>\n<li>공식적으로 지원되는 Model Zoo 모델들은 제공되는 예제 코드를 바로 사용 가능합니다.</li>\n<li>이외 모델도 <a href=\"https://github.com/rebellions-sw/rbln-model-zoo\" class=\"underline\" target=\"_blank\">Model Zoo 코드</a>를 참고하여 컴파일할 수 있습니다.</li>\n</ul>\n<p>지원하는 연산 목록을 미리 확인해보세요.</p>\n<ul>\n<li><a href=\"https://docs.rbln.ai/ko/misc/supported_ops_pytorch.html\" class=\"underline\" target=\"_blank\">PyTorch</a></li>\n<li><a href=\"https://docs.rbln.ai/ko/misc/supported_ops_tensorflow.html\" class=\"underline\" target=\"_blank\">TensorFlow</a></li>\n</ul>\n",
        "author": "Kwak Jiwon",
        "createdDate": "2025-04-07",
        "fileName": "ko/faq_2.ko.md",
        "order": "2"
      },
      {
        "title": "트랜스포머 모델(예: Llama, BERT)을 리벨리온 NPU에서 실행할 때 성능을 향상시키는 설정이나 권장 옵션이 있나요?",
        "slug": "트랜스포머-모델(예:-llama,-bert)을-리벨리온-npu에서-실행할-때-성능을-향상시키는-설정이나-권장-옵션이-있나요?",
        "tags": [
          "transformer",
          "llama",
          "bert"
        ],
        "body": "<p>트랜스포머 계열 모델의 성능을 극대화하려면 다음을 고려하세요:</p>\n<ul>\n<li><code>rbln_tensor_parallel_size</code> 값을 적절히 설정하여 NPU 병렬성 활용</li>\n<li>입력 시퀀스 길이 및 배치 크기 튜닝</li>\n</ul>\n",
        "author": "Kwak Jiwon",
        "createdDate": "2025-04-07",
        "fileName": "ko/faq_31.ko.md",
        "order": "3"
      },
      {
        "title": "RBLN Runtime APIs를 C/C++에서 사용할 수 있나요?",
        "slug": "rbln-runtime-apis를-c/c++에서-사용할-수-있나요?",
        "tags": [
          "c",
          "cpp",
          "compatibility"
        ],
        "body": "<p>RBLN SDK는 파이썬 런타임을 사용할 수 없거나 아주 낮은 지연시간을 요구하는 응용에 사용될 수 있도록 C/C++ 언어로 바인딩 된 런타임을 제공합니다.</p>\n<p><a href=\"https://docs.rbln.ai/ko/software/api/language_binding/c/installation.html\" class=\"underline\" target=\"_blank\">C/C++ 가이드</a>를 참고해주세요.</p>\n",
        "author": "Kwak Jiwon",
        "createdDate": "2025-04-07",
        "fileName": "ko/faq_32.ko.md",
        "order": "4"
      },
      {
        "title": "AI 프레임워크와의 버전 호환성을 어떻게 보장하나요?",
        "slug": "ai-프레임워크와의-버전-호환성을-어떻게-보장하나요?",
        "tags": [
          "framework",
          "compatibility",
          "api"
        ],
        "body": "<p>RBLN SDK 및 컴파일러는 주요 프레임워크의 최신 버전과의 API 호환성을 유지하도록 정기적으로 업데이트됩니다. 자세한 내용은 각 <a href=\"https://docs.rbln.ai/supports/release_note.html\" class=\"underline\" target=\"_blank\">릴리스 노트</a>를 참고해주세요.</p>\n",
        "author": "Kwak Jiwon",
        "createdDate": "2025-04-07",
        "fileName": "ko/faq_35.ko.md",
        "order": "5"
      },
      {
        "title": "어떤 PyTorch 기능과 호환되나요?",
        "slug": "어떤-pytorch-기능과-호환되나요?",
        "tags": [
          "pytorch",
          "compatibility",
          "features"
        ],
        "body": "<p>RBLN SDK는 PyTorch 기반 모델과의 높은 호환성을 제공합니다.</p>\n<ul>\n<li><code>torch.compile()</code> 지원: PyTorch 2.0의 <code>torch.compile()</code> 기능과 호환되며, TorchDynamo 및 TorchInductor 백엔드를 기반으로 컴파일된 모델을 처리할 수 있습니다.</li>\n<li>광범위한 연산자 지원: RBLN 컴파일러는 PyTorch 연산자의 대부분을 지원하며, <a href=\"https://docs.rbln.ai/misc/supported_ops_pytorch.html\" class=\"underline\" target=\"_blank\">지원 연산자 목록</a>을 통해 상세 내용을 확인할 수 있습니다. 주요 Vision, NLP, Audio 연산자도 포함되어 있어 다양한 딥러닝 모델에 활용 가능합니다.</li>\n<li>PyTorch Model Zoo 호환: ResNet, YOLO, LLaMA, BERT 등 <a href=\"https://docs.rbln.ai/misc/pytorch_modelzoo.html\" class=\"underline\" target=\"_blank\">PyTorch Model Zoo</a>의 대표적인 모델 다수가 지원됩니다.</li>\n<li>JIT/Scripted 모델 지원: TorchScript를 사용해 변환된 모델도 RBLN 컴파일러에서 처리할 수 있습니다.</li>\n</ul>\n",
        "author": "Kwak Jiwon",
        "createdDate": "2025-04-07",
        "fileName": "ko/faq_36.ko.md",
        "order": "6"
      },
      {
        "title": "RBLN Driver는 어떻게 설치하나요?",
        "slug": "rbln-driver는-어떻게-설치하나요?",
        "tags": [
          "rbln driver",
          "installation"
        ],
        "body": "<p>RBLN Driver는 제공된 <code>deb</code> 또는 <code>rpm</code> 설치 파일을 통해 설치할 수 있으며, 루트 권한이 필요합니다. 설치 시 커널 버전과 드라이버 호환성 확인이 요구됩니다.</p>\n<p>대부분의 경우 Driver가 미리 설치된 환경을 제공해 드립니다. 설치가 필요한 경우는 <a href=\"https://docs.rbln.ai/ko/getting_started/installation_guide.html?h=driver#installation\" class=\"underline\" target=\"_blank\">설치 가이드</a>를 참고하세요.</p>\n",
        "author": "Kwak Jiwon",
        "createdDate": "2025-04-07",
        "fileName": "ko/faq_8.ko.md",
        "order": 9999
      },
      {
        "title": "RBLN SDK는 어떻게 설치하나요?",
        "slug": "rbln-sdk는-어떻게-설치하나요?",
        "tags": [
          "rbln sdk",
          "installation"
        ],
        "body": "<p>RBLN SDK는 아래와 같이 파이썬(Python) 환경에서 간단하게 설치 할 수 있습니다.</p>\n<pre><code>pip3 install --extra-index-url https://pypi.rbln.ai/simple rebel-compiler==&lt;latest-version&gt; optimum-rbln==&lt;latest-version&gt; vllm-rbln==&lt;latest-version&gt;\n</code></pre>\n<p>최신 패키지 버전을 확인하려면 <a href=\"https://docs.rbln.ai/supports/release_note.html\" class=\"underline\" target=\"_blank\">릴리스 노트</a>를 참고해주세요. 사용자의 환경에 따라 추가적인 파이썬 패키지 의존성이 있을 수 있습니다.</p>\n",
        "author": "Kwak Jiwon",
        "createdDate": "2025-04-07",
        "fileName": "ko/faq_9.ko.md",
        "order": 9999
      }
    ]
  },
  {
    "category": "설치 및 설정",
    "lang": "ko",
    "faqs": [
      {
        "title": "RBLN Driver는 어떻게 설치하나요?",
        "slug": "rbln-driver는-어떻게-설치하나요?",
        "tags": [
          "rbln driver",
          "installation"
        ],
        "body": "<p>RBLN Driver는 제공된 <code>deb</code> 또는 <code>rpm</code> 설치 파일을 통해 설치할 수 있으며, 루트 권한이 필요합니다. 설치 시 커널 버전과 드라이버 호환성 확인이 요구됩니다.</p>\n<p>대부분의 경우 Driver가 미리 설치된 환경을 제공해 드립니다. 설치가 필요한 경우는 <a href=\"https://docs.rbln.ai/ko/getting_started/installation_guide.html?h=driver#installation\" class=\"underline\" target=\"_blank\">설치 가이드</a>를 참고하세요.</p>\n",
        "author": "Kwak Jiwon",
        "createdDate": "2025-04-07",
        "fileName": "ko/faq_8.ko.md",
        "order": "2"
      },
      {
        "title": "RBLN SDK는 어떻게 설치하나요?",
        "slug": "rbln-sdk는-어떻게-설치하나요?",
        "tags": [
          "rbln sdk",
          "installation"
        ],
        "body": "<p>RBLN SDK는 아래와 같이 파이썬(Python) 환경에서 간단하게 설치 할 수 있습니다.</p>\n<pre><code>pip3 install --extra-index-url https://pypi.rbln.ai/simple rebel-compiler==&lt;latest-version&gt; optimum-rbln==&lt;latest-version&gt; vllm-rbln==&lt;latest-version&gt;\n</code></pre>\n<p>최신 패키지 버전을 확인하려면 <a href=\"https://docs.rbln.ai/supports/release_note.html\" class=\"underline\" target=\"_blank\">릴리스 노트</a>를 참고해주세요. 사용자의 환경에 따라 추가적인 파이썬 패키지 의존성이 있을 수 있습니다.</p>\n",
        "author": "Kwak Jiwon",
        "createdDate": "2025-04-07",
        "fileName": "ko/faq_9.ko.md",
        "order": "2"
      },
      {
        "title": "RBLN SDK에서 요구하는 파이썬 버전이나 추가적인 의존성이 있나요?",
        "slug": "rbln-sdk에서-요구하는-파이썬-버전이나-추가적인-의존성이-있나요?",
        "tags": [
          "python",
          "dependencies"
        ],
        "body": "<p>기본적으로 파이썬(Python) 3.9 이상이 권장되며, numpy, torch, onnx 등 주요 패키지 의존성이 있습니다.</p>\n<p>지원되는  OS와 파이썬 버전을 <a href=\"https://docs.rbln.ai/supports/version_matrix.html\" class=\"underline\" target=\"_blank\">Support Matrix</a> 페이지를 확인하세요.\n요구되는 패키지는 모델에 따라 다르며, <a href=\"https://github.com/rebellions-sw/rbln-model-zoo\" class=\"underline\" target=\"_blank\">Model Zoo 코드</a>와 함께 포함된 <code>requirements.txt</code>를 참고해주세요.</p>\n",
        "author": "Kwak Jiwon",
        "createdDate": "2025-04-07",
        "fileName": "ko/faq_6.ko.md",
        "order": "4"
      },
      {
        "title": "RBLN SDK는 Windows에서 사용 가능한가요?",
        "slug": "rbln-sdk는-windows에서-사용-가능한가요?",
        "tags": [
          "windows",
          "linux"
        ],
        "body": "<p>현재 RBLN SDK는 Linux 환경에서만 지원됩니다. Windows 지원은 추후 로드맵에 따라 검토될 예정입니다.</p>\n<p>지원되는 OS와 파이썬(Python) 버전을 <a href=\"https://docs.rbln.ai/supports/version_matrix.html\" class=\"underline\" target=\"_blank\">Support Matrix</a> 페이지를 확인하세요.</p>\n",
        "author": "Kwak Jiwon",
        "createdDate": "2025-04-07",
        "fileName": "ko/faq_5.ko.md",
        "order": "5"
      },
      {
        "title": "드라이버/컴파일러를 업그레이드 하고 나서 제대로 동작하지 않아요.",
        "slug": "드라이버/컴파일러를-업그레이드-하고-나서-제대로-동작하지-않아요.",
        "tags": [
          "upgrade",
          "error",
          "version"
        ],
        "body": "<p>드라이버와 컴파일러의 버전 불일치로 인해 문제가 발생할 수 있습니다.</p>\n<ul>\n<li>RBLN SDK의 <a href=\"https://docs.rbln.ai/supports/release_note.html\" class=\"underline\" target=\"_blank\">릴리스 노트</a>를 참고하여 각 구성 요소가 호환되는 버전으로 설치되어 있는지 확인하세요.</li>\n<li>모든 라이브러리를 호환 버전에 맞춘 후, 모델을 다시 컴파일해 보시기 바랍니다.</li>\n</ul>\n",
        "author": "Kwak Jiwon",
        "createdDate": "2025-04-07",
        "fileName": "ko/faq_30.ko.md",
        "order": 9999
      },
      {
        "title": "트랜스포머 모델(예: Llama, BERT)을 리벨리온 NPU에서 실행할 때 성능을 향상시키는 설정이나 권장 옵션이 있나요?",
        "slug": "트랜스포머-모델(예:-llama,-bert)을-리벨리온-npu에서-실행할-때-성능을-향상시키는-설정이나-권장-옵션이-있나요?",
        "tags": [
          "transformer",
          "llama",
          "bert"
        ],
        "body": "<p>트랜스포머 계열 모델의 성능을 극대화하려면 다음을 고려하세요:</p>\n<ul>\n<li><code>rbln_tensor_parallel_size</code> 값을 적절히 설정하여 NPU 병렬성 활용</li>\n<li>입력 시퀀스 길이 및 배치 크기 튜닝</li>\n</ul>\n",
        "author": "Kwak Jiwon",
        "createdDate": "2025-04-07",
        "fileName": "ko/faq_31.ko.md",
        "order": 9999
      }
    ]
  },
  {
    "category": "서비스 활용/최적화",
    "lang": "ko",
    "faqs": [
      {
        "title": "NPU 여러 개를 분산해서 사용할 수 있나요?",
        "slug": "npu-여러-개를-분산해서-사용할-수-있나요?",
        "tags": [
          "npu",
          "multidevice"
        ],
        "body": "<p>RBLN SDK는 RSD (Rebellions Scalable Design)라고 명명된 tensor parallelism 기반의 분산 추론을 지원합니다.\n멀티-NPU가 지원되는 <a href=\"https://docs.rbln.ai/ko/software/optimum/optimum_rbln.html#multi-npu-rsd\" class=\"underline\" target=\"_blank\">모델 리스트</a>를 먼저 확인해주시고, 컴파일 방법은 제공된 <a href=\"https://docs.rbln.ai/ko/software/optimum/tutorial/llama3-8B.html#npu\" class=\"underline\" target=\"_blank\">예시</a>를 참고해주세요.</p>\n",
        "author": "Kwak Jiwon",
        "createdDate": "2025-04-07",
        "fileName": "ko/faq_11.ko.md",
        "order": "1"
      },
      {
        "title": "NPU에서 모델 성능을 측정하고 분석하는 방법은 무엇인가요?",
        "slug": "npu에서-모델-성능을-측정하고-분석하는-방법은-무엇인가요?",
        "tags": [
          "model",
          "performance",
          "analysis"
        ],
        "body": "<p>SDK에 포함된 <a href=\"https://docs.rbln.ai/ko/software/profiler/overview.html\" class=\"underline\" target=\"_blank\">프로파일러(Profiler)</a>를 통해 처리 시간(latency), 처리량(throughput), 메모리 사용량(memory usage) 등의 지표를 분석할 수 있습니다.</p>\n<p><a href=\"https://docs.rbln.ai/ko/software/system_management/device_management.html\" class=\"underline\" target=\"_blank\"><code>rbln-stat</code></a>을 이용하면 소모 전력(power)이나 활용률(utilization)도 확인할 수 있습니다.</p>\n",
        "author": "Kwak Jiwon",
        "createdDate": "2025-04-07",
        "fileName": "ko/\bfaq_12.ko.md",
        "order": "2"
      },
      {
        "title": "리벨리온 NPU에서 최적의 배치 크기를 결정하는 방법은 무엇인가요?",
        "slug": "리벨리온-npu에서-최적의-배치-크기를-결정하는-방법은-무엇인가요?",
        "tags": [
          "batch size"
        ],
        "body": "<p>사용하는 NPU의 종류, 서버 구성, 서비스 요구 사항 등에 따라 최적의 배치 크기가 다를 것으로 예상합니다. 프로파일러(Profiler) 도구를 활용하고 다양한 실험을 통해 튜닝 하는 것을 권장합니다.</p>\n",
        "author": "Kwak Jiwon",
        "createdDate": "2025-04-07",
        "fileName": "ko/faq_10.ko.md",
        "order": "3"
      },
      {
        "title": "프로파일링 및 최적화 도구가 제공되나요?",
        "slug": "프로파일링-및-최적화-도구가-제공되나요?",
        "tags": [
          "profiling",
          "tool",
          "optimization"
        ],
        "body": "<p>RBLN SDK에는 성능 병목 분석을 위한 RBLN 프로파일러(Profiler)가 포함되어 있으며, 실행 시간, 메모리 사용량, 연산 의존성 등의 주요 지표를 수집합니다.</p>\n<ul>\n<li><code>.pb</code> 형식의 트레이스 파일은 Perfetto로 시각화할 수 있습니다.</li>\n<li>병목 지점, 연산 간 의존성, 레이어별 처리시간(latency)등을 분석해 최적화 방향을 제시합니다.</li>\n</ul>\n<p>자세한 사용법은 <a href=\"https://docs.rbln.ai/ko/software/profiler/overview.html\" class=\"underline\" target=\"_blank\">프로파일러(Profiler) 가이드</a>를 참고하세요.</p>\n",
        "author": "Kwak Jiwon",
        "createdDate": "2025-04-07",
        "fileName": "ko/faq_13.ko.md",
        "order": "3"
      },
      {
        "title": "혼합 정밀(Mixed Precision) 모델을 지원하나요?",
        "slug": "혼합-정밀(mixed-precision)-모델을-지원하나요?",
        "tags": [
          "mixed precisions",
          "optimization"
        ],
        "body": "<p>네, Mixed Precision 모델도 지원합니다. 다만 최적화 수준은 모델 구조에 따라 달라질 수 있으며, 별도 가이드라인 제공이 필요합니다. 자세한 내용은 <a href=\"https://discuss.rebellions.ai\" class=\"underline\" target=\"_blank\">포럼</a>에 문의해주세요.</p>\n",
        "author": "Kwak Jiwon",
        "createdDate": "2025-04-07",
        "fileName": "ko/faq_16.ko.md",
        "order": "5"
      },
      {
        "title": "비디오 입력 파일(.mp4)은 어떻게 처리하나요?",
        "slug": "비디오-입력-파일(.mp4)은-어떻게-처리하나요?",
        "tags": [
          "mp4",
          "video",
          "optimization"
        ],
        "body": "<p>비디오 파일을 처리하기 위해서는 OpenCV(cv2)와 같은 라이브러리를 활용하여 .mp4 파일의 각 프레임을 이미지로 추출한 뒤, 이를 모델에 입력하는 방식으로 추론을 진행합니다.</p>\n<p>예를 들어, YOLOX와 같은 객체 탐지 모델을 사용할 경우 다음과 같은 절차를 따릅니다:</p>\n<ol>\n<li>cv2.VideoCapture로 비디오 파일을 로드</li>\n<li>프레임 단위로 이미지 추출</li>\n<li>각 프레임을 모델 입력 형식에 맞게 전처리</li>\n<li>모델을 통해 객체 탐지 수행</li>\n<li>결과를 시각화하여 저장 또는 실시간 출력</li>\n</ol>\n",
        "author": "Kwak Jiwon",
        "createdDate": "2025-04-07",
        "fileName": "ko/faq_14.md",
        "order": "6"
      },
      {
        "title": "어떤 FP16 포맷을 지원하나요? ",
        "slug": "어떤-fp16-포맷을-지원하나요?-",
        "tags": [
          "fp16",
          "optimization"
        ],
        "body": "<p>Bfloat16, IEEE754, Custom FP16를 지원합니다.</p>\n",
        "author": "Kwak Jiwon",
        "createdDate": "2025-04-07",
        "fileName": "ko/faq_17.ko.md",
        "order": 9999
      },
      {
        "title": "어떤 서빙 프레임워크를 지원하나요?",
        "slug": "어떤-서빙-프레임워크를-지원하나요?",
        "tags": [
          "cloud",
          "kubernetes",
          "serving framework"
        ],
        "body": "<p>RBLN SDK를 사용하면 <a href=\"https://docs.rbln.ai/ko/software/model_serving/vllm_support/vllm-rbln.html\" class=\"underline\" target=\"_blank\">vLLM</a>, Nvidia Triton Inference Server, 그리고 TorchServe 등의 서빙 프레임워크와 연동이 가능합니다. 컨테이너 기반 배포에는 <a href=\"https://github.com/rebellions-sw/rebel-k8s-device-plugin\" class=\"underline\" target=\"_blank\">쿠버네티스(Kubernetes)</a>와의 통합도 지원됩니다.</p>\n",
        "author": "Kwak Jiwon",
        "createdDate": "2025-04-07",
        "fileName": "ko/faq_26.ko.md",
        "order": 9999
      },
      {
        "title": "모델 추론 시 CPU 점유율이 너무 높아요.",
        "slug": "모델-추론-시-cpu-점유율이-너무-높아요.",
        "tags": [
          "cpu",
          "inference"
        ],
        "body": "<p><code>RBLN_NUM_THREADS</code> 환경 변수를 설정하여 모델 추론 시 사용하는 CPU 스레드 수를 제한할 수 있습니다. 적절한 스레드 수를 지정하면 CPU 부하를 줄이고 성능을 안정화할 수 있습니다.</p>\n<p><a href=\"https://docs.rbln.ai/ko/software/api/troubleshoot.html#1\" class=\"underline\" target=\"_blank\">관련 문서</a>를 참고해주세요.</p>\n",
        "author": "Kwak Jiwon",
        "createdDate": "2025-04-07",
        "fileName": "ko/faq_29.ko.md",
        "order": 9999
      },
      {
        "title": "쿠버네티스 지원하나요?",
        "slug": "쿠버네티스-지원하나요?",
        "tags": [
          "cloud",
          "kubernetes",
          "serving framework"
        ],
        "body": "<p>네, <a href=\"https://github.com/rebellions-sw/rebel-k8s-device-plugin\" class=\"underline\" target=\"_blank\">쿠버네티스(Kubernetes) 플러그인</a>을 통해 NPU 리소스를 활용할 수 있습니다.</p>\n",
        "author": "Kwak Jiwon",
        "createdDate": "2025-04-07",
        "fileName": "ko/faq_37.ko.md",
        "order": 9999
      }
    ]
  },
  {
    "category": "제품 정보/호환성",
    "lang": "ko",
    "faqs": [
      {
        "title": "ATOM과 REBEL은 어떻게 다른가요?",
        "slug": "atom과-rebel은-어떻게-다른가요?",
        "tags": [
          "rebel",
          "atom",
          "optimization"
        ],
        "body": "<p>둘 다 리벨리온의 AI 추론용 NPU이지만, REBEL은 차세대 제품으로 칩렛 기반으로 설계되었습니다. 자세한 비교표는 <a href=\"https://rebellions.ai/rebellions-product/rbln-ca25/\" class=\"underline\" target=\"_blank\">제품 페이지</a>에서 확인 가능합니다.</p>\n",
        "author": "Kwak Jiwon",
        "createdDate": "2025-04-07",
        "fileName": "ko/faq_20.ko.md",
        "order": "1"
      },
      {
        "title": "모델 훈련(Training)도 가능한가요?",
        "slug": "모델-훈련(training)도-가능한가요?",
        "tags": [
          "training",
          "inference"
        ],
        "body": "<p>현재 RBLN SDK는 추론(Inference) 전용이며, 향후 지원 계획이 구체화되면 로드맵을 통해 공지 예정입니다.</p>\n",
        "author": "Kwak Jiwon",
        "createdDate": "2025-04-07",
        "fileName": "ko/faq_19.ko.md",
        "order": "2"
      },
      {
        "title": "어떤 FP16 포맷을 지원하나요? ",
        "slug": "어떤-fp16-포맷을-지원하나요?-",
        "tags": [
          "fp16",
          "optimization"
        ],
        "body": "<p>Bfloat16, IEEE754, Custom FP16를 지원합니다.</p>\n",
        "author": "Kwak Jiwon",
        "createdDate": "2025-04-07",
        "fileName": "ko/faq_17.ko.md",
        "order": "3"
      },
      {
        "title": "쿠버네티스 지원하나요?",
        "slug": "쿠버네티스-지원하나요?",
        "tags": [
          "cloud",
          "kubernetes",
          "serving framework"
        ],
        "body": "<p>네, <a href=\"https://github.com/rebellions-sw/rebel-k8s-device-plugin\" class=\"underline\" target=\"_blank\">쿠버네티스(Kubernetes) 플러그인</a>을 통해 NPU 리소스를 활용할 수 있습니다.</p>\n",
        "author": "Kwak Jiwon",
        "createdDate": "2025-04-07",
        "fileName": "ko/faq_37.ko.md",
        "order": "4"
      },
      {
        "title": "어떤 서빙 프레임워크를 지원하나요?",
        "slug": "어떤-서빙-프레임워크를-지원하나요?",
        "tags": [
          "cloud",
          "kubernetes",
          "serving framework"
        ],
        "body": "<p>RBLN SDK를 사용하면 <a href=\"https://docs.rbln.ai/ko/software/model_serving/vllm_support/vllm-rbln.html\" class=\"underline\" target=\"_blank\">vLLM</a>, Nvidia Triton Inference Server, 그리고 TorchServe 등의 서빙 프레임워크와 연동이 가능합니다. 컨테이너 기반 배포에는 <a href=\"https://github.com/rebellions-sw/rebel-k8s-device-plugin\" class=\"underline\" target=\"_blank\">쿠버네티스(Kubernetes)</a>와의 통합도 지원됩니다.</p>\n",
        "author": "Kwak Jiwon",
        "createdDate": "2025-04-07",
        "fileName": "ko/faq_26.ko.md",
        "order": "5"
      },
      {
        "title": "NPU와 GPU의 차이점은 무엇인가요?",
        "slug": "npu와-gpu의-차이점은-무엇인가요?",
        "tags": [
          "npu",
          "gpu"
        ],
        "body": "<p>NPU(Neural Processing Unit)와 GPU(Graphics Processing Unit)는 모두 병렬 연산을 수행하지만, 최적화된 연산 방식과 사용 목적이 다릅니다.</p>\n<p>GPU는 원래 그래픽 렌더링을 위해 설계되었지만, 대규모 병렬 연산이 가능해 AI 학습(training)과 고성능 컴퓨팅(HPC)에 활용됩니다. 일반적으로 FP32/FP16 연산을 사용하며, CUDA 코어 및 Tensor 코어를 포함하여 다양한 연산을 지원합니다.\nNPU는 AI/딥러닝에 특화된 프로세서로, 저전력에서 효율적인 연산을 수행하도록 설계되었습니다. INT8, FP16과 같은 저비트 연산을 최적화하며, 신경망 연산을 가속하는 전용 하드웨어 구조를 가집니다.</p>\n",
        "author": "Kwak Jiwon",
        "createdDate": "2025-04-07",
        "fileName": "ko/faq_21.ko.md",
        "order": "6"
      },
      {
        "title": "NPU 여러 개를 분산해서 사용할 수 있나요?",
        "slug": "npu-여러-개를-분산해서-사용할-수-있나요?",
        "tags": [
          "npu",
          "multidevice"
        ],
        "body": "<p>RBLN SDK는 RSD (Rebellions Scalable Design)라고 명명된 tensor parallelism 기반의 분산 추론을 지원합니다.\n멀티-NPU가 지원되는 <a href=\"https://docs.rbln.ai/ko/software/optimum/optimum_rbln.html#multi-npu-rsd\" class=\"underline\" target=\"_blank\">모델 리스트</a>를 먼저 확인해주시고, 컴파일 방법은 제공된 <a href=\"https://docs.rbln.ai/ko/software/optimum/tutorial/llama3-8B.html#npu\" class=\"underline\" target=\"_blank\">예시</a>를 참고해주세요.</p>\n",
        "author": "Kwak Jiwon",
        "createdDate": "2025-04-07",
        "fileName": "ko/faq_11.ko.md",
        "order": 9999
      },
      {
        "title": "혼합 정밀(Mixed Precision) 모델을 지원하나요?",
        "slug": "혼합-정밀(mixed-precision)-모델을-지원하나요?",
        "tags": [
          "mixed precisions",
          "optimization"
        ],
        "body": "<p>네, Mixed Precision 모델도 지원합니다. 다만 최적화 수준은 모델 구조에 따라 달라질 수 있으며, 별도 가이드라인 제공이 필요합니다. 자세한 내용은 <a href=\"https://discuss.rebellions.ai\" class=\"underline\" target=\"_blank\">포럼</a>에 문의해주세요.</p>\n",
        "author": "Kwak Jiwon",
        "createdDate": "2025-04-07",
        "fileName": "ko/faq_16.ko.md",
        "order": 9999
      },
      {
        "title": "파인 튜닝(Fine-tuning) 및 추론을 최적화하는 방법은 무엇인가요?",
        "slug": "파인-튜닝(fine-tuning)-및-추론을-최적화하는-방법은-무엇인가요?",
        "tags": [
          "inference",
          "fine-tuning"
        ],
        "body": "<p>리벨리온 NPU는 추론 전용으로 설계되어 있어 현재 파인 튜닝은 불가능합니다.</p>\n<p>추론 성능을 극대화하기 위해 아래와 같은 최적화 전략을 권장합니다:</p>\n<ul>\n<li><p>Mixed Precision 및 양자화 사용: FP16 또는 INT8 양자화 모델을 활용하여 메모리 사용량과 연산 속도를 개선할 수 있습니다.</p>\n</li>\n<li><p>배치 크기 조정: 모델 특성과 입력 데이터에 맞는 최적의 배치 크기를 찾아 처리량(throughput)을 높이세요.</p>\n</li>\n<li><p>모델 구조 리팩토링: Layer fusion과 불필요한 연산 제거를 통해 연산 그래프를 간소화하면 성능이 향상됩니다.</p>\n</li>\n<li><p>이중 버퍼링(Double Buffering): <code>AsyncRuntime</code>의 이중 버퍼링을 활용하여 성능을 향상시킬 수 있습니다.</p>\n</li>\n<li><p>LLM 서빙 시 Continuous Batching 적용: 대형 언어 모델 서빙에는 <code>vllm-rbln</code>을 활용한 continuous batching 기법을 적용하여 NPU 활용률을 극대화할 수 있습니다.</p>\n</li>\n</ul>\n",
        "author": "Kwak Jiwon",
        "createdDate": "2025-04-07",
        "fileName": "ko/faq_22.ko.md",
        "order": 9999
      },
      {
        "title": "RBLN Runtime APIs를 C/C++에서 사용할 수 있나요?",
        "slug": "rbln-runtime-apis를-c/c++에서-사용할-수-있나요?",
        "tags": [
          "c",
          "cpp",
          "compatibility"
        ],
        "body": "<p>RBLN SDK는 파이썬 런타임을 사용할 수 없거나 아주 낮은 지연시간을 요구하는 응용에 사용될 수 있도록 C/C++ 언어로 바인딩 된 런타임을 제공합니다.</p>\n<p><a href=\"https://docs.rbln.ai/ko/software/api/language_binding/c/installation.html\" class=\"underline\" target=\"_blank\">C/C++ 가이드</a>를 참고해주세요.</p>\n",
        "author": "Kwak Jiwon",
        "createdDate": "2025-04-07",
        "fileName": "ko/faq_32.ko.md",
        "order": 9999
      },
      {
        "title": "AI 프레임워크와의 버전 호환성을 어떻게 보장하나요?",
        "slug": "ai-프레임워크와의-버전-호환성을-어떻게-보장하나요?",
        "tags": [
          "framework",
          "compatibility",
          "api"
        ],
        "body": "<p>RBLN SDK 및 컴파일러는 주요 프레임워크의 최신 버전과의 API 호환성을 유지하도록 정기적으로 업데이트됩니다. 자세한 내용은 각 <a href=\"https://docs.rbln.ai/supports/release_note.html\" class=\"underline\" target=\"_blank\">릴리스 노트</a>를 참고해주세요.</p>\n",
        "author": "Kwak Jiwon",
        "createdDate": "2025-04-07",
        "fileName": "ko/faq_35.ko.md",
        "order": 9999
      },
      {
        "title": "어떤 PyTorch 기능과 호환되나요?",
        "slug": "어떤-pytorch-기능과-호환되나요?",
        "tags": [
          "pytorch",
          "compatibility",
          "features"
        ],
        "body": "<p>RBLN SDK는 PyTorch 기반 모델과의 높은 호환성을 제공합니다.</p>\n<ul>\n<li><code>torch.compile()</code> 지원: PyTorch 2.0의 <code>torch.compile()</code> 기능과 호환되며, TorchDynamo 및 TorchInductor 백엔드를 기반으로 컴파일된 모델을 처리할 수 있습니다.</li>\n<li>광범위한 연산자 지원: RBLN 컴파일러는 PyTorch 연산자의 대부분을 지원하며, <a href=\"https://docs.rbln.ai/misc/supported_ops_pytorch.html\" class=\"underline\" target=\"_blank\">지원 연산자 목록</a>을 통해 상세 내용을 확인할 수 있습니다. 주요 Vision, NLP, Audio 연산자도 포함되어 있어 다양한 딥러닝 모델에 활용 가능합니다.</li>\n<li>PyTorch Model Zoo 호환: ResNet, YOLO, LLaMA, BERT 등 <a href=\"https://docs.rbln.ai/misc/pytorch_modelzoo.html\" class=\"underline\" target=\"_blank\">PyTorch Model Zoo</a>의 대표적인 모델 다수가 지원됩니다.</li>\n<li>JIT/Scripted 모델 지원: TorchScript를 사용해 변환된 모델도 RBLN 컴파일러에서 처리할 수 있습니다.</li>\n</ul>\n",
        "author": "Kwak Jiwon",
        "createdDate": "2025-04-07",
        "fileName": "ko/faq_36.ko.md",
        "order": 9999
      },
      {
        "title": "RBLN SDK는 Windows에서 사용 가능한가요?",
        "slug": "rbln-sdk는-windows에서-사용-가능한가요?",
        "tags": [
          "windows",
          "linux"
        ],
        "body": "<p>현재 RBLN SDK는 Linux 환경에서만 지원됩니다. Windows 지원은 추후 로드맵에 따라 검토될 예정입니다.</p>\n<p>지원되는 OS와 파이썬(Python) 버전을 <a href=\"https://docs.rbln.ai/supports/version_matrix.html\" class=\"underline\" target=\"_blank\">Support Matrix</a> 페이지를 확인하세요.</p>\n",
        "author": "Kwak Jiwon",
        "createdDate": "2025-04-07",
        "fileName": "ko/faq_5.ko.md",
        "order": 9999
      },
      {
        "title": "RBLN SDK에서 요구하는 파이썬 버전이나 추가적인 의존성이 있나요?",
        "slug": "rbln-sdk에서-요구하는-파이썬-버전이나-추가적인-의존성이-있나요?",
        "tags": [
          "python",
          "dependencies"
        ],
        "body": "<p>기본적으로 파이썬(Python) 3.9 이상이 권장되며, numpy, torch, onnx 등 주요 패키지 의존성이 있습니다.</p>\n<p>지원되는  OS와 파이썬 버전을 <a href=\"https://docs.rbln.ai/supports/version_matrix.html\" class=\"underline\" target=\"_blank\">Support Matrix</a> 페이지를 확인하세요.\n요구되는 패키지는 모델에 따라 다르며, <a href=\"https://github.com/rebellions-sw/rbln-model-zoo\" class=\"underline\" target=\"_blank\">Model Zoo 코드</a>와 함께 포함된 <code>requirements.txt</code>를 참고해주세요.</p>\n",
        "author": "Kwak Jiwon",
        "createdDate": "2025-04-07",
        "fileName": "ko/faq_6.ko.md",
        "order": 9999
      },
      {
        "title": "RBLN SDK는 어떤 AI 프레임워크와 라이브러리를 지원하나요?",
        "slug": "rbln-sdk는-어떤-ai-프레임워크와-라이브러리를-지원하나요?",
        "tags": [
          "frameworks",
          "libraries"
        ],
        "body": "<p>RBLN SDK는 PyTorch 및 TensorFlow 기반 모델을 지원하며, Hugging Face Transformers/Diffusers 라이브러리와의 연동도 가능합니다.</p>\n<p>지속적인 업데이트를 통해 주요 AI 프레임워크와의 호환성을 강화하고 있습니다.</p>\n",
        "author": "Kwak Jiwon",
        "createdDate": "2025-04-07",
        "fileName": "ko/faq_7.ko.md",
        "order": 9999
      }
    ]
  },
  {
    "category": "지원 및 문제 해결",
    "lang": "ko",
    "faqs": [
      {
        "title": "사용자 커뮤니티 포럼이나 지원 채널이 있나요?",
        "slug": "사용자-커뮤니티-포럼이나-지원-채널이-있나요?",
        "tags": [
          "forum",
          "community"
        ],
        "body": "<p>네, <a href=\"https://discuss.rebellions.ai/\" class=\"underline\" target=\"_blank\">포럼</a>을 통해 기술 문의 및 커뮤니티 소통이 가능합니다. <a href=\"mailto:client_support@rebellions.ai\" class=\"underline\" target=\"_blank\">여기</a>로 메일을 보내주셔도 됩니다.</p>\n",
        "author": "Kwak Jiwon",
        "createdDate": "2025-04-07",
        "fileName": "ko/faq_23.ko.md",
        "order": "1"
      },
      {
        "title": "NPU 펌웨어 또는 드라이버 업데이트 주기는 어떻게 되나요?",
        "slug": "npu-펌웨어-또는-드라이버-업데이트-주기는-어떻게-되나요?",
        "tags": [
          "support",
          "sdk",
          "update"
        ],
        "body": "<p>SDK는 약 한 달 주기로, 드라이버는 약 3개월 주기로 업데이트되며, 일정은 변경될 수 있습니다. 상세 내용은 최신 <a href=\"https://docs.rbln.ai/supports/release_note.html\" class=\"underline\" target=\"_blank\">릴리스 노트</a>를 참고해주세요.</p>\n",
        "author": "Kwak Jiwon",
        "createdDate": "2025-04-07",
        "fileName": "ko/faq_24.ko.md",
        "order": "2"
      },
      {
        "title": "모델 컴파일이 실패했습니다.",
        "slug": "모델-컴파일이-실패했습니다.",
        "tags": [
          "model-compile",
          "error"
        ],
        "body": "<p>현재 <a href=\"https://github.com/rebellions-sw/rbln-model-zoo\" class=\"underline\" target=\"_blank\">RBLN Model Zoo</a>에서 공식적으로 지원되는 모델의 경우, 제공된 컴파일 및 추론 예제 코드를 사용하실 수 있습니다.</p>\n<p>변형된 모델 또는 Model Zoo에 포함되지 않은 모델을 사용할 경우 기술지원이 제한적이며 컴파일이 실패 할 수 있습니다.\n우선 <a href=\"https://docs.rbln.ai/ko/misc/error_code.html\" class=\"underline\" target=\"_blank\">에러 코드</a>를 확인하여 원인을 파악해 보고, 추가적인 지원이 필요한 경우 <a href=\"discuss.rebellions.ai\" class=\"underline\" target=\"_blank\">개발자 포럼</a>을 통해 문의해주세요.</p>\n",
        "author": "Kwak Jiwon",
        "createdDate": "2025-04-07",
        "fileName": "ko/faq_27.ko.md",
        "order": "3"
      },
      {
        "title": "언어모델을 컴파일/추론할 때 에러가 발생합니다.",
        "slug": "언어모델을-컴파일/추론할-때-에러가-발생합니다.",
        "tags": [
          "compile",
          "error"
        ],
        "body": "<p>다음 항목들을 확인해 보세요:</p>\n<ul>\n<li>메모리 사용량: 컴파일 시 시스템 메모리가 부족하면 컴파일이 실패할 수 있습니다.</li>\n<li>NPU 설정 확인: <code>rbln_tensor_parallel_size</code> 값이 시스템에 실제로 장착된 NPU 개수보다 크지 않은지 확인하세요. 터미널에서 <code>rbln-stat</code> 명령어를 실행하면 NPU 수를 확인할 수 있습니다.</li>\n<li>도커(Docker) 환경: <a href=\"https://docs.rbln.ai/ko/software/system_management/docker.html\" class=\"underline\" target=\"_blank\">도커 가이드</a>를 참고해주세요.</li>\n</ul>\n",
        "author": "Kwak Jiwon",
        "createdDate": "2025-04-07",
        "fileName": "ko/faq_28.ko.md",
        "order": "4"
      },
      {
        "title": "모델 추론 시 CPU 점유율이 너무 높아요.",
        "slug": "모델-추론-시-cpu-점유율이-너무-높아요.",
        "tags": [
          "cpu",
          "inference"
        ],
        "body": "<p><code>RBLN_NUM_THREADS</code> 환경 변수를 설정하여 모델 추론 시 사용하는 CPU 스레드 수를 제한할 수 있습니다. 적절한 스레드 수를 지정하면 CPU 부하를 줄이고 성능을 안정화할 수 있습니다.</p>\n<p><a href=\"https://docs.rbln.ai/ko/software/api/troubleshoot.html#1\" class=\"underline\" target=\"_blank\">관련 문서</a>를 참고해주세요.</p>\n",
        "author": "Kwak Jiwon",
        "createdDate": "2025-04-07",
        "fileName": "ko/faq_29.ko.md",
        "order": "5"
      },
      {
        "title": "드라이버/컴파일러를 업그레이드 하고 나서 제대로 동작하지 않아요.",
        "slug": "드라이버/컴파일러를-업그레이드-하고-나서-제대로-동작하지-않아요.",
        "tags": [
          "upgrade",
          "error",
          "version"
        ],
        "body": "<p>드라이버와 컴파일러의 버전 불일치로 인해 문제가 발생할 수 있습니다.</p>\n<ul>\n<li>RBLN SDK의 <a href=\"https://docs.rbln.ai/supports/release_note.html\" class=\"underline\" target=\"_blank\">릴리스 노트</a>를 참고하여 각 구성 요소가 호환되는 버전으로 설치되어 있는지 확인하세요.</li>\n<li>모든 라이브러리를 호환 버전에 맞춘 후, 모델을 다시 컴파일해 보시기 바랍니다.</li>\n</ul>\n",
        "author": "Kwak Jiwon",
        "createdDate": "2025-04-07",
        "fileName": "ko/faq_30.ko.md",
        "order": "6"
      }
    ]
  }
]